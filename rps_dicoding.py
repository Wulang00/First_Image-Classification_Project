# -*- coding: utf-8 -*-
"""RPS_Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dYskbHNFKQa4_YME5cnZ_nJeBDEBjh1W

## Importing Lib & Additional Content
"""

#Install Content
!pip install split_folders

#Lib
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import zipfile, os
import splitfolders
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import shutil
import sklearn

#additional
from tensorflow import keras
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from google.colab import files
from sklearn.model_selection import train_test_split

"""##Download Datasets"""

!wget --no-check-certificate https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip -O rockpaperscissors.zip

#Unzip Content and move dict
local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('RPS')
zip_ref.close()

#Simply make doc
os.mkdir('data')

#Make Train, Test and Validation Folder
source = '/content/data'
destination = '/content/RPS/rockpaperscissors'

shutil = (source, destination) #<-- this gonna make source file goes to destination

#gonna split file
splitfolders.ratio('/content/RPS/rockpaperscissors/rps-cv-images', '/content/RPS/rockpaperscissors/data', seed=1, ratio=(.6, .4))

"""##Let's Start Coding"""

base_dir = 'RPS/rockpaperscissors/data'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')
os.listdir('RPS/rockpaperscissors/data/train')
os.listdir('RPS/rockpaperscissors/data/val')

"""Make Train Code"""

train_rock = os.path.join(train_dir, 'train')
train_scissors = os.path.join(train_dir, 'scissors')
train_paper = os.path.join(train_dir, 'paper')
 
validation_rock = os.path.join(validation_dir, 'rock')
validation_scissors = os.path.join(validation_dir, 'scissors')
validation_paper = os.path.join(validation_dir, 'paper')

"""Make Image deligate for GPU"""

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    shear_range=0.2, 
  zoom_range=0.2, 
  horizontal_flip=True) 

test_datagen = ImageDataGenerator(
  rescale=1./255, 
  shear_range=0.2,
  zoom_range=0.2, 
  horizontal_flip=True)

train_generator = train_datagen.flow_from_directory(
  train_dir,
  target_size=(224, 224),
  batch_size=32, 
  color_mode='rgb', #should be RGB (Red, Green & Blue)
  class_mode='categorical', 
  shuffle = True, 
  seed=42) 
validation_generator = test_datagen.flow_from_directory(
  validation_dir,
  target_size=(224, 224),
  batch_size=32,
  color_mode='rgb',
  class_mode='categorical',
  shuffle = True,
  seed=42)

"""##Visual your datasets"""

sample_train_images, _ = next(train_generator)
sample_val_images, _ = next(validation_generator)

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

plotImages(sample_train_images[:5])
plotImages(sample_val_images[:5])

"""##Get to the code"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax') #there some others activition for dense. check the code for your project
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

history = model.fit(train_generator, 
          steps_per_epoch=25, 
          epochs=20, 
          validation_data=validation_generator,
          validation_steps=5,
          verbose=1)

terima = history.history['accuracy']
val_terima = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(terima, color='blue')
plt.plot(val_terima, color='red')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(loss, color='blue')
plt.plot(val_loss, color='red')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""##TEST IMAGE BEFORE SUMITING"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(224,224))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)

  if classes[0,0]!=0:
    print('PAPER')
  elif classes[0,1]!=0:
    print('ROCK')
  else:
    print('SCISSORS')

"""##Accuracy Check"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(acc, color='green')
plt.plot(val_acc, color='grey')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(loss, color='green')
plt.plot(val_loss, color='grey')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()